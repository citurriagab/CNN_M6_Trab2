{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/citurriagab/CNN_M6_Trab2/blob/main/KMNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f7e3dd",
      "metadata": {
        "id": "a2f7e3dd"
      },
      "source": [
        "### Trabajo N° 2\n",
        "\n",
        "#### Deep Learning \n",
        "\n",
        "**Análisis Supervisado**\n",
        "\n",
        "**Clasificación**\n",
        "\n",
        "*Carla Iturriaga Barrios*\n",
        "\n",
        "*Rodrigo Lefin Carrasco*\n",
        "\n",
        "Septiembre, 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Presentación del proyecto.\n",
        "\n",
        "*Una empresa de consultoria que presta servicios de traducción, utilizando herramientas de Deep Learning, tiene un nuevo cliente que requiere **identificar letras del japonés clásico pero desde imágenes**.*\n",
        "\n",
        "**Fuente de datos**: *Dataset correspondiente a imagenes de datos reimpresos del japonés clásico \"Kuzushiji\" obtenido directamente de la librería pytorch*"
      ],
      "metadata": {
        "id": "OQQ5SQU-nwfB"
      },
      "id": "OQQ5SQU-nwfB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objetivo del proyecto.\n",
        "\n",
        "1. *Construir un modelo que sea capaz de clasificar y categorizar en letras del japonés clásico un conjunto de imágenes de la letra desde textos reimpresos.*"
      ],
      "metadata": {
        "id": "fOACytchpSS6"
      },
      "id": "fOACytchpSS6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación del entorno"
      ],
      "metadata": {
        "id": "5cAciMwnuxWa"
      },
      "id": "5cAciMwnuxWa"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "2b2f4160",
      "metadata": {
        "id": "2b2f4160"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import datetime\n",
        "import torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: Datos"
      ],
      "metadata": {
        "id": "TNHtQKbHu26S"
      },
      "id": "TNHtQKbHu26S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Los siguientes datos corresponden a una base de 70.000 imagenes de 28x28 con la reimpresión de textos japoneses. La categorización de ellas se divide en 10 clases correspondientes a letras del japonés clásico, tales como: **'o', 'ki', 'su', 'tsu', etc**.*"
      ],
      "metadata": {
        "id": "Ac85q8x0rEZF"
      },
      "id": "Ac85q8x0rEZF"
    },
    {
      "cell_type": "code",
      "source": [
        "path = './data/'\n",
        "\n",
        "# configuración de dataset de entrenamiento y de prueba\n",
        "df = datasets.KMNIST(path, train=True, download=True)\n",
        "df_test = datasets.KMNIST(path, train=False, download=True)"
      ],
      "metadata": {
        "id": "LxWubopMwATj"
      },
      "id": "LxWubopMwATj",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Largo del dataset\n",
        "print('Registros de entrenamiento:', len(df))\n",
        "print('Registros de prueba:', len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZdFVC0lxooW",
        "outputId": "87c91662-d4aa-481e-a714-483b5ddfaa3f"
      },
      "id": "gZdFVC0lxooW",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registros de entrenamiento: 60000\n",
            "Registros de prueba: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificación de las etiquetas/label\n",
        "df.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3nNhXlx0d_",
        "outputId": "d83aa08b-6d2b-4117-eed1-6c0b3b4e82e8"
      },
      "id": "3u3nNhXlx0d_",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'ki', 'su', 'tsu', 'na', 'ha', 'ma', 'ya', 're', 'wo']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Previsualización de imagenes del dataset\n",
        "\n",
        "*En adelante, se muestran algunos ejemplares de los registros del dataset KMNIST, correspondiente a la letra en compañía con su etiqueta o clase*"
      ],
      "metadata": {
        "id": "SQHUf--KtdDS"
      },
      "id": "SQHUf--KtdDS"
    },
    {
      "cell_type": "code",
      "source": [
        "#Previsualización de una imagen dentro del dataset\n",
        "img, label = df[10]\n",
        "plt.imshow(img)\n",
        "print('la siguiente imagen corresponde al label:', label, 'correspondiente a:', df.classes[label])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uRzgApSDxFAj",
        "outputId": "8b4d752c-b345-4877-cc85-7d574d4fc268"
      },
      "id": "uRzgApSDxFAj",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la siguiente imagen corresponde al label: 5 correspondiente a: ha\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Previsualización de una imagen dentro del dataset\n",
        "img2, label2 = df[90]\n",
        "plt.imshow(img2)\n",
        "print('la siguiente imagen corresponde al label:', label2, 'correspondiente a:', df.classes[label2])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UqTbNX9AxkPW",
        "outputId": "5ff3921a-8511-41eb-fdba-37ff216e4acc"
      },
      "id": "UqTbNX9AxkPW",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la siguiente imagen corresponde al label: 2 correspondiente a: su\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Previsualización de una imagen dentro del dataset\n",
        "img3, label3 = df[25000]\n",
        "plt.imshow(img3)\n",
        "print('la siguiente imagen corresponde al label:', label3, 'correspondiente a:', df.classes[label3])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "g0YxXIrjuiWe",
        "outputId": "28ab1899-ae1f-4870-c4b7-62e686d7d071"
      },
      "id": "g0YxXIrjuiWe",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la siguiente imagen corresponde al label: 3 correspondiente a: tsu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformación y Normalización de imagenes a tensor de PyTorch\n",
        "\n",
        "*Para seguir con el análisis y modelamiento, es requerido transformar los registros del dataset desde imágenes a tensores y, posteriormente, normalizar sus medidas de promedio y desviación estándar*"
      ],
      "metadata": {
        "id": "VorRhgpyuqJ1"
      },
      "id": "VorRhgpyuqJ1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar data a tensor de pytorch y normalizar\n",
        "df = datasets.KMNIST(\n",
        "    path, train=True, download=True, \n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
        "        transforms.Normalize((0.5,),(0.5,)),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
        "        \n",
        "    ])\n",
        ")\n",
        "\n",
        "df_test = datasets.KMNIST(\n",
        "    path, train=False, download=True, \n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
        "        transforms.Normalize((0.5,),(0.5,)),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
        "\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "wucg13EczE0U"
      },
      "id": "wucg13EczE0U",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Información del dataset"
      ],
      "metadata": {
        "id": "_wQhcBNYvXpQ"
      },
      "id": "_wQhcBNYvXpQ"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Entrenamiento: ', df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02z7M7An8gOs",
        "outputId": "c0ed66fc-f7f6-4180-ae92-1a81755ed3cf"
      },
      "id": "02z7M7An8gOs",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento:  Dataset KMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data/\n",
            "    Split: Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prueba: ', df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6raNRzykyNnj",
        "outputId": "c27e305a-189e-45d4-c285-c4cd1d75f8fd"
      },
      "id": "6raNRzykyNnj",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prueba:  Dataset KMNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data/\n",
            "    Split: Test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualización de los registros transformados en Tensores\n",
        "\n",
        "*En adelante, se genera una demostración gráfica del nuevo registro tensor*"
      ],
      "metadata": {
        "id": "a-V_wfTmwqva"
      },
      "id": "a-V_wfTmwqva"
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la imagen transformada\n",
        "img_t, label = df[10]\n",
        "#plt.imshow(img_t.permute(1,2,0))\n",
        "plt.imshow(torchvision.utils.make_grid(img_t, nrow=5).permute(1, 2, 0))\n",
        "print('La siguiente imagen corresponde al label:', label, 'correspondiente a:', df.classes[label])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jzSQMzCb0Aq0",
        "outputId": "f0d8c5f9-7339-479a-f72f-b5d68367a8db"
      },
      "id": "jzSQMzCb0Aq0",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La siguiente imagen corresponde al label: 5 correspondiente a: ha\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Modelo\n",
        "\n",
        "*Dado el tipo de registros (imágenes) e información con la que se está trabajando en el presente proyecto, se decide configurar y entrenar el modelo **CNN** (Convolutional Neural Network)*\n",
        "\n",
        "*Para ello, se desarrolla, a continuación, la red neuronal con **2 hiden layers**, donde el registro de entrada al primer layer corresponde a un input de 3 dimensiones y la última **salida correspondería a 10 clases**.*"
      ],
      "metadata": {
        "id": "3LP7wNot6kSL"
      },
      "id": "3LP7wNot6kSL"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "a7cfc5a9",
      "metadata": {
        "id": "a7cfc5a9"
      },
      "outputs": [],
      "source": [
        "# Model \n",
        "class CNN(nn.Module):\n",
        "    \"\"\"Cada arquitectura es una forma funcional de la red.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) # convolutional layer\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1) # convolutional layer\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)                     # Fully connected\n",
        "        self.fc2 = nn.Linear(32, 10)                             # Fully connected\n",
        "\n",
        "    def forward(self, x): # input img\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)        # max pooling\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)      # max pooling\n",
        "        out = out.view(-1, 8 * 8 * 8)                           # tranform the out\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out  # dim: number of class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*En la siguiente **función de entrenamiento**, queda definido genericamente el proceso en bucle al que deben someterse las imágenes/tensores para entrenar el modelo, donde se tiene como input la cantidad de iteraciones (epochs), el modelo (CNN), optimizador, la función de error y la definición de los batches*"
      ],
      "metadata": {
        "id": "Inqy_deA0BfY"
      },
      "id": "Inqy_deA0BfY"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "43d63284",
      "metadata": {
        "id": "43d63284"
      },
      "outputs": [],
      "source": [
        "# Training function \n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    loss_list = []\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0 \n",
        "        for imgs, labels in train_loader:  # batch \n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()               # backpro\n",
        "            optimizer.step()              # update w\n",
        "            \n",
        "            loss_train += loss.item()\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch,\n",
        "            loss_train / len(train_loader)))\n",
        "            loss_list.append(loss_train / len(train_loader))\n",
        "    return loss_list\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenando el modelo...\n",
        "\n",
        "*Ya con el modelo y las funciones definidas, el set de datos KMNIST debe entrenar el modelo, donde:*\n",
        "\n",
        "* *El **modelo** definido, como anteriormente se mencionó es el de **Convolutional Neural Network**, dado que los registros pertenecen a la categoria **imagenes**.*\n",
        "\n",
        "* *El **Optimizador** definido será **Adam**, dado que al ser una versión más actual y al estar construido en base a SGD, se espera un rendimiento superior en sus restulados*\n",
        "\n",
        "* *En cuanto a la **Función de pérdida**, se utilizará **Cross Entropy** ya que este proyecto es de clasificación*"
      ],
      "metadata": {
        "id": "zefiuhZJwhPw"
      },
      "id": "zefiuhZJwhPw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hiperparámetros (W)**\n",
        "\n",
        "*En términos de los hiperparametros del modelo CNN:*\n",
        "\n",
        "- **Batches**: Se optará por **32**, para la división de la base de datos.\n",
        "\n",
        "- **Learning Rate (lr)**: Este se definirá como **0.01**, con la intención de búsqueda del valor óptimo en una rapidez mediana.\n",
        "\n",
        "- **Epochs**: La cantidad de iteraciones serán **50**, dado que se requiere un número alto para la búsqueda del valor óptimo y disminuir lo más posible el error."
      ],
      "metadata": {
        "id": "N2rrI38D6jJs"
      },
      "id": "N2rrI38D6jJs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(df, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "UZM8HydN6viW"
      },
      "id": "UZM8HydN6viW",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "174fa7c5",
      "metadata": {
        "id": "174fa7c5",
        "outputId": "5bcf3386-2f6a-4fb4-9e52-6344b060984b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-f271ea5079f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-61824c9b6621>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-925176b87221>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# max pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# max pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m                           \u001b[0;31m# tranform the out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 512]' is invalid for input of size 12544"
          ]
        }
      ],
      "source": [
        "# Run, traning\n",
        "model = CNN()                                      # call our cnn class\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # Stochastic gradient descent\n",
        "loss_fn = nn.CrossEntropyLoss()                    # Loss function\n",
        "\n",
        "Loss1 = training_loop(\n",
        "    n_epochs = 50,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualización de la función de pérdida (Loss F.)\n",
        "\n",
        "*El siguiente gráfico presenta la curvatura que va tomando el error al avanzar las iteraciones del modelo (epochs), de ello se puede mencionar que:*\n",
        "\n",
        "*En primera instancia, los errores toman valores altos que van disminuyendo al iterar cada vez más, ............\"llegando a la iteración XXXX, loss function toma un valor que se puede considerar como óptimo...............*"
      ],
      "metadata": {
        "id": "wi5ytEpm7dSl"
      },
      "id": "wi5ytEpm7dSl"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "fbb51c29",
      "metadata": {
        "id": "fbb51c29",
        "outputId": "01f5dba7-1679-4072-fc2e-0b5436cf92fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-6b80a7c83999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch(x10)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Loss1' is not defined"
          ]
        }
      ],
      "source": [
        "# plot loss\n",
        "plt.plot(Loss1)\n",
        "plt.xlabel('Epoch(x10)')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Métricas y Resultados"
      ],
      "metadata": {
        "id": "l2m9Y_es6q6S"
      },
      "id": "l2m9Y_es6q6S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Métricas.**\n",
        "\n",
        "*Dentro de las métricas a calcular en el presente proyecto para definir qué tan bueno es el modelo desarrolado, se tienen las siguientes:*\n",
        "\n",
        "- Accuracy\n",
        "\n",
        "- F1\n",
        "\n",
        "- AUC\n",
        "\n",
        "- Precision\n",
        "\n",
        "- Recall"
      ],
      "metadata": {
        "id": "QYDZtA2G9A8o"
      },
      "id": "QYDZtA2G9A8o"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gn1Qk-c89A6G"
      },
      "id": "Gn1Qk-c89A6G"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "5a795183",
      "metadata": {
        "id": "5a795183",
        "outputId": "3cb2dd9e-c44c-4563-cc83-35e6e298d9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-3b0d2010bf5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy {}: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-3b0d2010bf5e>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# metrics: Acc, F1, AUC, Precision, Recall,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy {}: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (49) must match the size of tensor b (64) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "# Testing metric\n",
        "train_loader = torch.utils.data.DataLoader(df, batch_size=32,\n",
        "                                            shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(df_test, batch_size=32,\n",
        "                                            shuffle=False)\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                total += labels.shape[0]\n",
        "                # metrics: Acc, F1, AUC, Precision, Recall, \n",
        "                correct += int((predicted == labels).sum())\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        #print(\"F1 Score: ....\")\n",
        "        #print(\"AUC: .......\")\n",
        "        #print(\"Precision: ....\")\n",
        "        #print(\"Recall: .......\")\n",
        "\n",
        "validate(model, train_loader, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*De acuerdo a los resultados anteriores, se define que el modelo CNN construido para clasificar en letras del japonés clásico imagenes de texto reimpreso es ......................... BUENO/MALO ......................., esto fundamentado en los valores de:*\n",
        "\n",
        "*  .......................... \"Accuracy\" que obtuvo un valor XXXXXX, indicando que es capaz de acertar en el XX% de los casos......................*\n",
        "\n",
        "* *Por otro lado, se puede mencionar, también, que F1 Score alcanza un nivel de .................XX, traduciendose en que el modelo ............(relacionarlo con las imagenes y letras japonesas)..................................*\n",
        "\n",
        "* .....................\"otras metricas*............................."
      ],
      "metadata": {
        "id": "ztQG8yyh98p4"
      },
      "id": "ztQG8yyh98p4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}